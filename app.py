import streamlit as st
import pandas as pd
import numpy as np
import re
from io import BytesIO
import xlsxwriter
import zipfile

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å…³é”®è¯å“ç‰ŒåŒ¹é…å·¥å…·",
    page_icon="ğŸ”",
    layout="wide"
)

# åˆå§‹åŒ–session state
if 'custom_rules' not in st.session_state:
    st.session_state.custom_rules = pd.DataFrame(columns=['å“ç‰Œåç§°', 'åŒ¹é…å…³é”®è¯'])
if 'product_data' not in st.session_state:
    st.session_state.product_data = None
if 'brand_data' not in st.session_state:
    st.session_state.brand_data = None
if 'matched_results' not in st.session_state:
    st.session_state.matched_results = None

def process_product_data(df):
    """å¤„ç†äº§å“æ•°æ®ï¼Œè®¡ç®—æ’åå’Œç´¯è®¡å æ¯”"""
    # æ•°æ®æ¸…æ´—å’Œç±»å‹è½¬æ¢
    df_clean = df.copy()
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ['å…³é”®è¯', 'æœˆæœç´¢é‡']
    missing_columns = [col for col in required_columns if col not in df_clean.columns]
    if missing_columns:
        st.error(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—ï¼š{missing_columns}")
        return None
    
    # æ¸…ç†æœˆæœç´¢é‡åˆ—
    df_clean['æœˆæœç´¢é‡'] = pd.to_numeric(df_clean['æœˆæœç´¢é‡'], errors='coerce')
    
    # ç§»é™¤æœˆæœç´¢é‡ä¸ºNaNæˆ–0çš„è¡Œ
    df_clean = df_clean.dropna(subset=['æœˆæœç´¢é‡'])
    df_clean = df_clean[df_clean['æœˆæœç´¢é‡'] > 0]
    
    if df_clean.empty:
        st.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æœˆæœç´¢é‡æ•°æ®")
        return None
    
    # æ’åºå’Œè®¡ç®—
    df_sorted = df_clean.sort_values('æœˆæœç´¢é‡', ascending=False).reset_index(drop=True)
    df_sorted['Rank'] = range(1, len(df_sorted) + 1)
    df_sorted['æœˆæœç´¢é‡ç´¯è®¡å’Œ'] = df_sorted['æœˆæœç´¢é‡'].cumsum()
    df_sorted['æœˆæœç´¢é‡ç´¯è®¡å æ¯”'] = df_sorted['æœˆæœç´¢é‡ç´¯è®¡å’Œ'] / df_sorted['æœˆæœç´¢é‡'].sum()
    return df_sorted

def match_brands(product_df, brand_df, custom_rules_df):
    """æ‰§è¡Œå“ç‰ŒåŒ¹é…é€»è¾‘"""
    # æ•°æ®éªŒè¯
    if product_df is None or product_df.empty:
        st.error("âŒ äº§å“æ•°æ®ä¸ºç©º")
        return None
    
    if brand_df is None or brand_df.empty:
        st.error("âŒ å“ç‰Œæ•°æ®ä¸ºç©º")
        return None
    
    # å‡†å¤‡æ•°æ®
    result_df = product_df[['å…³é”®è¯', 'æœˆæœç´¢é‡']].copy()
    result_df['keyword_lower'] = result_df['å…³é”®è¯'].astype(str).str.lower()
    
    # å‡†å¤‡å“ç‰Œè¯ï¼ˆè½¬å°å†™ï¼‰
    brand_list = brand_df['å“ç‰Œåç§°'].astype(str).str.lower().tolist()
    
    # å‡†å¤‡æ‰‹åŠ¨è§„åˆ™
    manual_map = {}
    if not custom_rules_df.empty:
        for _, row in custom_rules_df.iterrows():
            brand_name = str(row['å“ç‰Œåç§°'])
            keywords = [kw.strip().lower() for kw in str(row['åŒ¹é…å…³é”®è¯']).split(',') if kw.strip()]
            for kw in keywords:
                manual_map[kw] = brand_name
    
    # æ‰§è¡ŒåŒ¹é…
    result_df['å“ç‰Œåç§°'] = None
    result_df['å“ç‰Œ'] = None
    result_df['è¯æ€§'] = 'Non-Branded KWs'
    
    for idx, row in result_df.iterrows():
        keyword_lower = row['keyword_lower']
        matched_brand = None
        matched_term = None
        
        # 1. ä¼˜å…ˆæ£€æŸ¥æ‰‹åŠ¨è§„åˆ™ï¼ˆç²¾å‡†åŒ¹é…ï¼Œæ•´è¯åŒ¹é…ï¼‰
        for manual_kw, manual_brand in manual_map.items():
            if manual_kw:
                # ä½¿ç”¨æ­£åˆ™æ•´è¯åŒ¹é…ï¼Œå¿½ç•¥å¤§å°å†™
                pattern = r'(?<!\w)' + re.escape(manual_kw) + r'(?!\w)'
                if re.search(pattern, keyword_lower, re.IGNORECASE):
                    matched_brand = manual_brand
                    matched_term = manual_kw
                    break
        
        # 2. å¦‚æœæ‰‹åŠ¨è§„åˆ™æ²¡åŒ¹é…åˆ°ï¼Œæ£€æŸ¥å“ç‰Œè¯åº“ï¼ˆç²¾å‡†åŒ¹é…ï¼Œæ•´è¯åŒ¹é…ï¼‰
        if not matched_brand:
            for brand in brand_list:
                if brand:
                    pattern = r'(?<!\w)' + re.escape(brand) + r'(?!\w)'
                    if re.search(pattern, keyword_lower, re.IGNORECASE):
                        # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹å“ç‰Œåç§°
                        original_brand = brand_df[brand_df['å“ç‰Œåç§°'].str.lower() == brand]['å“ç‰Œåç§°'].iloc[0]
                        matched_brand = original_brand
                        matched_term = brand
                        break
        
        # 3. æ›´æ–°ç»“æœ
        if matched_brand:
            result_df.at[idx, 'å“ç‰Œåç§°'] = matched_brand
            result_df.at[idx, 'å“ç‰Œ'] = matched_term
            result_df.at[idx, 'è¯æ€§'] = 'Branded KWs'
    
    # æ·»åŠ ç‰¹æ€§å‚æ•°åˆ—
    result_df['ç‰¹æ€§å‚æ•°'] = None
    
    # æ¸…ç†ä¸´æ—¶åˆ—
    result_df = result_df.drop('keyword_lower', axis=1)
    
    return result_df

def create_download_file(df):
    """åˆ›å»ºExcelä¸‹è½½æ–‡ä»¶"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, sheet_name='å“ç‰ŒåŒ¹é…ç»“æœ', index=False)
    return output.getvalue()

# ä¸»ç•Œé¢
st.title("ğŸ” å…³é”®è¯å“ç‰ŒåŒ¹é…å·¥å…·")
st.markdown("**å¼€å‘ç»´æŠ¤ï¼šIDCéƒ¨é—¨**")

# ä¾§è¾¹æ 
with st.sidebar:
    st.image("https://upload.wikimedia.org/wikipedia/commons/9/9c/Anker_logo.svg", width=200)
    
    st.header("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
    
    # äº§å“å…³é”®è¯æ–‡ä»¶ä¸Šä¼ 
    product_file = st.file_uploader(
        "ä¸Šä¼ äº§å“å…³é”®è¯æ–‡ä»¶",
        type=['xlsx', 'xls'],
        help="è¯·ä¸Šä¼ åŒ…å«å…³é”®è¯å’Œæœˆæœç´¢é‡çš„Excelæ–‡ä»¶"
    )
    
    # å“ç‰Œè¯æ–‡ä»¶ä¸Šä¼ 
    brand_file = st.file_uploader(
        "ä¸Šä¼ æ¬§é¹­å“ç‰Œè¯æ•°æ®æ–‡ä»¶",
        type=['xlsx', 'xls'],
        help="è¯·ä¸Šä¼ åŒ…å«å“ç‰Œåç§°çš„Excelæ–‡ä»¶"
    )
    
    st.header("âš™ï¸ æ‰‹åŠ¨è§„åˆ™é…ç½®")
    
    # æ‰‹åŠ¨æ·»åŠ å“ç‰Œè§„åˆ™
    with st.form("add_rule_form"):
        custom_brand = st.text_input("å½’å±å“ç‰Œå")
        custom_keywords = st.text_input("åŒ¹é…å…³é”®è¯ï¼ˆè‹±æ–‡é€—å·åˆ†éš”ï¼‰")
        submitted = st.form_submit_button("æ·»åŠ å“ç‰Œè§„åˆ™")
        
        if submitted and custom_brand and custom_keywords:
            new_rule = pd.DataFrame({
                'å“ç‰Œåç§°': [custom_brand],
                'åŒ¹é…å…³é”®è¯': [custom_keywords]
            })
            st.session_state.custom_rules = pd.concat([st.session_state.custom_rules, new_rule], ignore_index=True)
            st.success("è§„åˆ™æ·»åŠ æˆåŠŸï¼")
    
    # æ˜¾ç¤ºè‡ªå®šä¹‰è§„åˆ™
    if not st.session_state.custom_rules.empty:
        st.subheader("å½“å‰è§„åˆ™")
        st.dataframe(st.session_state.custom_rules, hide_index=True)
        
        if st.button("æ¸…ç©ºæ‰€æœ‰è§„åˆ™"):
            st.session_state.custom_rules = pd.DataFrame(columns=['å“ç‰Œåç§°', 'åŒ¹é…å…³é”®è¯'])
            st.rerun()

# å¤„ç†æ–‡ä»¶ä¸Šä¼ 
if product_file:
    try:
        # è·³è¿‡å‰ä¸¤è¡Œè¯»å–Excel
        df = pd.read_excel(product_file, skiprows=2)
        
        # æ˜¾ç¤ºåŸå§‹æ•°æ®çš„åˆ—åï¼Œå¸®åŠ©ç”¨æˆ·äº†è§£æ•°æ®ç»“æ„
        st.info(f"ğŸ“‹ æ£€æµ‹åˆ°çš„åˆ—åï¼š{list(df.columns)}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„åˆ—
        if 'å…³é”®è¯' not in df.columns or 'æœˆæœç´¢é‡' not in df.columns:
            st.error("âŒ æ–‡ä»¶å¿…é¡»åŒ…å«'å…³é”®è¯'å’Œ'æœˆæœç´¢é‡'åˆ—")
            st.info("ğŸ’¡ è¯·ç¡®ä¿Excelæ–‡ä»¶åŒ…å«æ­£ç¡®çš„åˆ—å")
        else:
            st.session_state.product_data = df
            st.success("âœ… äº§å“å…³é”®è¯æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            
    except Exception as e:
        st.error(f"âŒ äº§å“å…³é”®è¯æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        st.info("ğŸ’¡ è¯·ç¡®ä¿æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„Excelæ ¼å¼(.xlsxæˆ–.xls)")

if brand_file:
    try:
        brand_df = pd.read_excel(brand_file)
        
        # æ˜¾ç¤ºåŸå§‹æ•°æ®çš„åˆ—å
        st.info(f"ğŸ“‹ æ£€æµ‹åˆ°çš„åˆ—åï¼š{list(brand_df.columns)}")
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦çš„åˆ—
        if 'å“ç‰Œåç§°' not in brand_df.columns:
            st.error("âŒ æ–‡ä»¶å¿…é¡»åŒ…å«'å“ç‰Œåç§°'åˆ—")
            st.info("ğŸ’¡ è¯·ç¡®ä¿Excelæ–‡ä»¶åŒ…å«æ­£ç¡®çš„åˆ—å")
        else:
            # è¿‡æ»¤ç©ºå€¼å¹¶å»é‡
            st.session_state.brand_data = brand_df.dropna(subset=['å“ç‰Œåç§°']).drop_duplicates(subset=['å“ç‰Œåç§°']).reset_index(drop=True)
            st.success("âœ… å“ç‰Œè¯æ•°æ®æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            
    except Exception as e:
        st.error(f"âŒ å“ç‰Œè¯æ•°æ®æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        st.info("ğŸ’¡ è¯·ç¡®ä¿æ–‡ä»¶æ˜¯æœ‰æ•ˆçš„Excelæ ¼å¼(.xlsxæˆ–.xls)")

# ä¸»å†…å®¹åŒºåŸŸ
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ“Š äº§å“å…³é”®è¯æ’å", "ğŸ·ï¸ å“ç‰Œè¯æ•°æ®", "ğŸ¯ å“ç‰ŒåŒ¹é…ç»“æœ", "ğŸ”§ ASINå»é‡å·¥å…·", "ğŸ“‚ æ‰¹é‡åˆå¹¶ZIPæ–‡ä»¶", "ğŸ“ æ‰¹é‡åˆå¹¶æ–‡ä»¶"])

with tab1:
    st.header("äº§å“å…³é”®è¯æ’å")
    
    if st.session_state.product_data is not None:
        processed_data = process_product_data(st.session_state.product_data)
        
        if processed_data is not None:
            # æ˜¾ç¤º60%ç´¯è®¡å æ¯”çš„æ’åæç¤º
            percent_60_data = processed_data[processed_data['æœˆæœç´¢é‡ç´¯è®¡å æ¯”'] >= 0.6]
            if not percent_60_data.empty:
                rank_60_percent = percent_60_data.iloc[0]['Rank']
                st.info(f"ğŸ“ˆ å½“æœˆæœç´¢é‡ç´¯è®¡å æ¯”è¾¾åˆ° 60% æ—¶çš„å…³é”®è¯æ’åä¸ºï¼š**{int(rank_60_percent)}**")
            else:
                st.info("ğŸ“ˆ æ‰€æœ‰å…³é”®è¯çš„ç´¯è®¡å æ¯”éƒ½æœªè¾¾åˆ° 60%")
            
            # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
            display_columns = [col for col in processed_data.columns if col not in ['æœˆæœç´¢é‡ç´¯è®¡å æ¯”', 'æœˆæœç´¢é‡ç´¯è®¡å’Œ']]
            st.dataframe(
                processed_data[display_columns],
                hide_index=True,
                use_container_width=True
            )
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»å…³é”®è¯æ•°", len(processed_data))
            with col2:
                st.metric("æ€»æœˆæœç´¢é‡", f"{processed_data['æœˆæœç´¢é‡'].sum():,}")
            with col3:
                st.metric("å¹³å‡æœˆæœç´¢é‡", f"{processed_data['æœˆæœç´¢é‡'].mean():.0f}")
        else:
            st.error("âŒ æ•°æ®å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
    else:
        st.info("è¯·å…ˆä¸Šä¼ äº§å“å…³é”®è¯æ–‡ä»¶")

with tab2:
    st.header("å“ç‰Œè¯æ•°æ®")
    
    if st.session_state.brand_data is not None:
        st.dataframe(
            st.session_state.brand_data[['å“ç‰Œåç§°']],
            hide_index=True,
            use_container_width=True
        )
        
        st.metric("å“ç‰Œæ€»æ•°", len(st.session_state.brand_data))
    else:
        st.info("è¯·å…ˆä¸Šä¼ å“ç‰Œè¯æ•°æ®æ–‡ä»¶")

with tab3:
    st.header("å“ç‰ŒåŒ¹é…ç»“æœ")
    
    # è¿è¡ŒåŒ¹é…æŒ‰é’®
    if st.button("ğŸš€ è¿è¡Œå“ç‰ŒåŒ¹é…", type="primary", use_container_width=True):
        if st.session_state.product_data is not None and st.session_state.brand_data is not None:
            with st.spinner("æ­£åœ¨æ‰§è¡Œå“ç‰ŒåŒ¹é…..."):
                st.session_state.matched_results = match_brands(
                    st.session_state.product_data,
                    st.session_state.brand_data,
                    st.session_state.custom_rules
                )
            st.success("âœ… å“ç‰ŒåŒ¹é…å®Œæˆï¼")
        else:
            st.error("âŒ è¯·å…ˆä¸Šä¼ äº§å“å…³é”®è¯æ–‡ä»¶å’Œå“ç‰Œè¯æ•°æ®æ–‡ä»¶")
    
    # æ˜¾ç¤ºåŒ¹é…ç»“æœ
    if st.session_state.matched_results is not None:
        # ç»Ÿè®¡ä¿¡æ¯
        total_keywords = len(st.session_state.matched_results)
        branded_keywords = len(st.session_state.matched_results[st.session_state.matched_results['è¯æ€§'] == 'Branded KWs'])
        non_branded_keywords = total_keywords - branded_keywords
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»å…³é”®è¯", total_keywords)
        with col2:
            st.metric("å“ç‰Œè¯", branded_keywords)
        with col3:
            st.metric("éå“ç‰Œè¯", non_branded_keywords)
        with col4:
            st.metric("å“ç‰Œè¯å æ¯”", f"{branded_keywords/total_keywords*100:.1f}%")
        
        # ç­›é€‰é€‰é¡¹
        col1, col2 = st.columns(2)
        with col1:
            word_type_filter = st.selectbox(
                "ç­›é€‰è¯æ€§",
                options=["å…¨éƒ¨", "Branded KWs", "Non-Branded KWs"]
            )
        with col2:
            brand_filter = st.selectbox(
                "ç­›é€‰å“ç‰Œ",
                options=["å…¨éƒ¨"] + list(st.session_state.matched_results['å“ç‰Œåç§°'].dropna().unique())
            )
        
        # åº”ç”¨ç­›é€‰
        filtered_results = st.session_state.matched_results.copy()
        if word_type_filter != "å…¨éƒ¨":
            filtered_results = filtered_results[filtered_results['è¯æ€§'] == word_type_filter]
        if brand_filter != "å…¨éƒ¨":
            filtered_results = filtered_results[filtered_results['å“ç‰Œåç§°'] == brand_filter]
        
        # æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®
        st.dataframe(
            filtered_results,
            hide_index=True,
            use_container_width=True
        )
        
        # ä¸‹è½½æŒ‰é’®
        if st.button("ğŸ“¥ ä¸‹è½½å“ç‰ŒåŒ¹é…ç»“æœ", use_container_width=True):
            excel_file = create_download_file(st.session_state.matched_results)
            st.download_button(
                label="ä¸‹è½½Excelæ–‡ä»¶",
                data=excel_file,
                file_name=f"å“ç‰ŒåŒ¹é…ç»“æœ_{pd.Timestamp.now().strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
    else:
        st.info("è¯·ç‚¹å‡»'è¿è¡Œå“ç‰ŒåŒ¹é…'æŒ‰é’®å¼€å§‹åŒ¹é…")

with tab4:
    st.header("ğŸ”§ ASINå»é‡å·¥å…·")
    
    # ASINè¾“å…¥åŒºåŸŸ
    st.subheader("ğŸ“ è¾“å…¥ASIN")
    asin_input = st.text_area(
        "è¯·è¾“å…¥ASINï¼ˆæ”¯æŒæ¢è¡Œã€ç©ºæ ¼ã€é€—å·ç­‰åˆ†éš”ç¬¦ï¼‰",
        height=200,
        placeholder="è¯·è¾“å…¥ASINï¼Œä¾‹å¦‚ï¼š\nB08N5WRWNW\nB08N5KWB9H\nB08N5KWB9H\nB08N5WRWNW"
    )
    
    # å»é‡æŒ‰é’®
    if st.button("ğŸ”„ æ‰§è¡Œå»é‡", type="primary", use_container_width=True):
        if asin_input.strip():
            # å¤„ç†è¾“å…¥çš„ASIN
            # æ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼šæ¢è¡Œã€ç©ºæ ¼ã€é€—å·ã€åˆ†å·ã€åˆ¶è¡¨ç¬¦
            asin_list = re.split(r'[\n\s,;\t]+', asin_input.strip())
            # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å’Œæ¸…ç†ASINæ ¼å¼
            asin_list = [asin.strip().upper() for asin in asin_list if asin.strip()]
            
            # è®°å½•å»é‡å‰çš„æ•°é‡
            original_count = len(asin_list)
            
            # å»é‡
            unique_asins = list(dict.fromkeys(asin_list))  # ä¿æŒé¡ºåºçš„å»é‡
            
            # è®°å½•å»é‡åçš„æ•°é‡
            unique_count = len(unique_asins)
            
            # ä¿å­˜ç»“æœåˆ°session state
            st.session_state.asin_results = {
                'original_count': original_count,
                'unique_count': unique_count,
                'unique_asins': unique_asins
            }
            
            st.success(f"âœ… å»é‡å®Œæˆï¼å»é‡å‰ï¼š{original_count}ä¸ªï¼Œå»é‡åï¼š{unique_count}ä¸ª")
        else:
            st.error("âŒ è¯·è¾“å…¥ASIN")
    
    # æ˜¾ç¤ºå»é‡ç»“æœ
    if hasattr(st.session_state, 'asin_results') and st.session_state.asin_results:
        results = st.session_state.asin_results
        
        st.subheader("ğŸ“Š å»é‡ç»“æœ")
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å»é‡å‰æ•°é‡", results['original_count'])
        with col2:
            st.metric("å»é‡åæ•°é‡", results['unique_count'])
        with col3:
            removed_count = results['original_count'] - results['unique_count']
            st.metric("é‡å¤æ•°é‡", removed_count)
        
        # æ˜¾ç¤ºå»é‡åçš„ASIN
        st.subheader("ğŸ¯ å»é‡åçš„ASIN")
        
        # å°†ASINç”¨ç©ºæ ¼è¿æ¥
        asin_text = ' '.join(results['unique_asins'])
        
        # åˆ›å»ºå¯å¤åˆ¶çš„æ–‡æœ¬æ¡†
        st.text_area(
            "å»é‡åçš„ASINï¼ˆç”¨ç©ºæ ¼åˆ†éš”ï¼‰",
            value=asin_text,
            height=100,
            help="ç‚¹å‡»æ–‡æœ¬æ¡†å†…çš„å†…å®¹å¯ä»¥å…¨é€‰å¤åˆ¶"
        )
        
        # å¤åˆ¶æŒ‰é’®
        if st.button("ğŸ“‹ å¤åˆ¶åˆ°å‰ªè´´æ¿", use_container_width=True):
            st.write("ğŸ’¡ è¯·æ‰‹åŠ¨é€‰æ‹©ä¸Šæ–¹æ–‡æœ¬æ¡†ä¸­çš„å†…å®¹å¹¶å¤åˆ¶")
        
        # æ˜¾ç¤ºè¯¦ç»†çš„ASINåˆ—è¡¨
        st.subheader("ğŸ“‹ è¯¦ç»†åˆ—è¡¨")
        st.dataframe(
            pd.DataFrame({
                'åºå·': range(1, len(results['unique_asins']) + 1),
                'ASIN': results['unique_asins']
            }),
            hide_index=True,
            use_container_width=True
        )
    else:
        st.info("è¯·åœ¨è¾“å…¥æ¡†ä¸­è¾“å…¥ASINï¼Œç„¶åç‚¹å‡»'æ‰§è¡Œå»é‡'æŒ‰é’®")

with tab5:
    st.header("ğŸ“‚ æ‰¹é‡åˆå¹¶ZIPæ–‡ä»¶")
    st.markdown("ä¸Šä¼ å¤šä¸ªzipæ–‡ä»¶ï¼ˆæ¯ä¸ªzipå†…ä»…åŒ…å«ä¸€ä¸ªcsvæˆ–xlsxæ–‡ä»¶ï¼‰ï¼Œè‡ªåŠ¨åˆå¹¶å¹¶ç”¨zipæ–‡ä»¶åä½œä¸º'æ—¶é—´'åˆ—")

    uploaded_zips = st.file_uploader(
        "è¯·ä¸Šä¼ zipæ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰",
        type=["zip"],
        accept_multiple_files=True
    )

    if uploaded_zips:
        all_data = []
        error_files = []
        for zip_file in uploaded_zips:
            try:
                with zipfile.ZipFile(zip_file) as z:
                    # åªå¤„ç†ç¬¬ä¸€ä¸ªcsvæˆ–xlsxæ–‡ä»¶
                    file_list = [f for f in z.namelist() if f.lower().endswith(('.csv', '.xlsx'))]
                    if not file_list:
                        error_files.append(zip_file.name)
                        continue
                    file_name = file_list[0]
                    with z.open(file_name) as f:
                        if file_name.lower().endswith('.csv'):
                            df = pd.read_csv(f)
                        else:
                            df = pd.read_excel(f)
                    # å¢åŠ "æ—¶é—´"åˆ—ï¼Œå–zipæ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰
                    df['æ—¶é—´'] = zip_file.name.rsplit('.', 1)[0]
                    all_data.append(df)
            except Exception as e:
                error_files.append(zip_file.name)
        if all_data:
            merged_df = pd.concat(all_data, ignore_index=True)
            st.success(f"åˆå¹¶æˆåŠŸï¼Œå…± {len(all_data)} ä¸ªzipæ–‡ä»¶ï¼Œåˆè®¡ {len(merged_df)} è¡Œæ•°æ®ã€‚")
            st.dataframe(merged_df, use_container_width=True)
            # ä¸‹è½½æŒ‰é’®
            towrite = BytesIO()
            merged_df.to_excel(towrite, index=False)
            towrite.seek(0)
            st.download_button(
                label="ä¸‹è½½åˆå¹¶ç»“æœExcel",
                data=towrite,
                file_name="åˆå¹¶ç»“æœ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        else:
            st.warning("æ²¡æœ‰æˆåŠŸåˆå¹¶çš„æ•°æ®ï¼Œè¯·æ£€æŸ¥ä¸Šä¼ çš„zipæ–‡ä»¶æ ¼å¼ã€‚")
        if error_files:
            st.error(f"ä»¥ä¸‹zipæ–‡ä»¶å¤„ç†å¤±è´¥æˆ–æœªæ‰¾åˆ°csv/xlsxæ–‡ä»¶ï¼š{', '.join(error_files)}")
    else:
        st.info("è¯·ä¸Šä¼ éœ€è¦åˆå¹¶çš„zipæ–‡ä»¶ã€‚")

with tab6:
    st.header("ğŸ“ æ‰¹é‡åˆå¹¶æ–‡ä»¶")
    st.markdown("ä¸Šä¼ å¤šä¸ªxlsxæˆ–csvæ–‡ä»¶ï¼Œè‡ªåŠ¨åˆå¹¶å¹¶ç”¨æ–‡ä»¶åä½œä¸º'æ—¶é—´'åˆ—æ”¾åœ¨ç¬¬ä¸€åˆ—")

    uploaded_files = st.file_uploader(
        "è¯·ä¸Šä¼ xlsxæˆ–csvæ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰",
        type=["xlsx", "xls", "csv"],
        accept_multiple_files=True
    )

    if uploaded_files:
        all_data = []
        error_files = []
        
        for file in uploaded_files:
            try:
                # æ ¹æ®æ–‡ä»¶æ‰©å±•åè¯»å–æ•°æ®
                if file.name.lower().endswith('.csv'):
                    df = pd.read_csv(file)
                else:  # xlsx or xls
                    df = pd.read_excel(file)
                
                # è·å–æ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰ä½œä¸ºæ—¶é—´åˆ—
                time_column = file.name.rsplit('.', 1)[0]
                
                # æ·»åŠ æ—¶é—´åˆ—åˆ°ç¬¬ä¸€åˆ—
                df.insert(0, 'æ—¶é—´', time_column)
                
                all_data.append(df)
                st.success(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶ï¼š{file.name}")
                
            except Exception as e:
                error_files.append(file.name)
                st.error(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ï¼š{file.name} - {str(e)}")
        
        if all_data:
            # åˆå¹¶æ‰€æœ‰æ•°æ®
            merged_df = pd.concat(all_data, ignore_index=True)
            
            st.success(f"ğŸ‰ åˆå¹¶æˆåŠŸï¼å…±å¤„ç† {len(all_data)} ä¸ªæ–‡ä»¶ï¼Œåˆè®¡ {len(merged_df)} è¡Œæ•°æ®")
            
            # è°ƒè¯•ä¿¡æ¯
            st.info(f"è°ƒè¯•ï¼šall_dataé•¿åº¦ = {len(all_data)}, merged_dfå½¢çŠ¶ = {merged_df.shape}")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å¤„ç†æ–‡ä»¶æ•°", len(all_data))
            with col2:
                st.metric("æ€»è¡Œæ•°", len(merged_df))
            with col3:
                st.metric("æ—¶é—´åˆ—å”¯ä¸€å€¼", merged_df['æ—¶é—´'].nunique())
            
            # æ˜¾ç¤ºåˆå¹¶åçš„æ•°æ®
            st.subheader("ğŸ“Š åˆå¹¶ç»“æœé¢„è§ˆ")
            st.dataframe(merged_df, use_container_width=True)
            
            # æ˜¾ç¤ºæ—¶é—´åˆ—ç»Ÿè®¡
            st.subheader("ğŸ“… æ—¶é—´åˆ—ç»Ÿè®¡")
            time_stats = merged_df['æ—¶é—´'].value_counts().reset_index()
            time_stats.columns = ['æ—¶é—´', 'è¡Œæ•°']
            st.dataframe(time_stats, hide_index=True, use_container_width=True)
            
            # ä¸‹è½½æŒ‰é’®
            st.subheader("ğŸ“¥ ä¸‹è½½åˆå¹¶ç»“æœ")
            
            # è°ƒè¯•ä¿¡æ¯
            st.info("æ­£åœ¨ç”Ÿæˆä¸‹è½½æ–‡ä»¶...")
            
            # Excelä¸‹è½½
            excel_output = BytesIO()
            merged_df.to_excel(excel_output, index=False)
            excel_output.seek(0)
            
            st.download_button(
                label="ğŸ“Š ä¸‹è½½Excelæ–‡ä»¶",
                data=excel_output.getvalue(),
                file_name=f"æ‰¹é‡åˆå¹¶ç»“æœ_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
            
            # CSVä¸‹è½½
            csv_output = BytesIO()
            merged_df.to_csv(csv_output, index=False, encoding='utf-8-sig')
            csv_output.seek(0)
            
            st.download_button(
                label="ğŸ“„ ä¸‹è½½CSVæ–‡ä»¶",
                data=csv_output.getvalue(),
                file_name=f"æ‰¹é‡åˆå¹¶ç»“æœ_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        else:
            st.warning("âš ï¸ æ²¡æœ‰æˆåŠŸåˆå¹¶çš„æ•°æ®ï¼Œè¯·æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼")
        
        if error_files:
            st.error(f"âŒ ä»¥ä¸‹æ–‡ä»¶å¤„ç†å¤±è´¥ï¼š{', '.join(error_files)}")
    else:
        st.info("ğŸ“ è¯·ä¸Šä¼ éœ€è¦åˆå¹¶çš„xlsxæˆ–csvæ–‡ä»¶")

# é¡µè„š
st.markdown("---")
st.markdown("ğŸ’¡ **ä½¿ç”¨è¯´æ˜**ï¼š")
st.markdown("""
1. ä¸Šä¼ äº§å“å…³é”®è¯Excelæ–‡ä»¶ï¼ˆéœ€åŒ…å«'å…³é”®è¯'å’Œ'æœˆæœç´¢é‡'åˆ—ï¼‰
2. ä¸Šä¼ å“ç‰Œè¯Excelæ–‡ä»¶ï¼ˆéœ€åŒ…å«'å“ç‰Œåç§°'åˆ—ï¼‰
3. å¯é€‰ï¼šæ·»åŠ æ‰‹åŠ¨åŒ¹é…è§„åˆ™
4. ç‚¹å‡»'è¿è¡Œå“ç‰ŒåŒ¹é…'æ‰§è¡ŒåŒ¹é…
5. æŸ¥çœ‹ç»“æœå¹¶ä¸‹è½½Excelæ–‡ä»¶
""")